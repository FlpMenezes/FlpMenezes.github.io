<<<<<<< HEAD
---
title: "Relatório 04"
author: "Felipe Henrique"
date: "01/05/2025"
header-includes:
  - \usepackage{titling}
  - \pretitle{\begin{center}
    \includegraphics[width=2in,height=2in]{ufsj.png}\LARGE\\}
  - \posttitle{\end{center}}
toc-title: "Sumário"
output:
  
  html_document:
    theme: journal
    highlight: tango
    toc: yes
    number_sections: yes
    includes:
      in_header: logo.html
  pdf_document:
    
    toc: yes
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
--- 

# Objetivo

Este relatório tem como objetivo examinar um experimento conduzido em um Delineamento Inteiramente Casualizado (DIC). Para isso, é preciso apresentar uma análise descritiva tanto geral quanto por tratamento, incluindo medidas como média, desvio padrão e coeficiente de variação. Além disso, deve-se elaborar um gráfico boxplot para visualização dos dados. A análise deve ser complementada com uma ANOVA, expondo as hipóteses nula e alternativa, a tabela da análise de variância e uma avaliação gráfica dos resíduos.

# Desenvolvimento

Para trabalhar neste relatório, será necessário utilizar o banco de dados abaixo proposto pelo professor. Com ele, devemos avaliar o Erro médio de medição de 3 tipos de sensores: Ultrassônico, Infravermelho e Indutivo. Nele, temos 3 tratamentos, com 5 repetições por sensor.

```{r}
# Banco de dados
sensores <- c(rep("Ultrassonico", 5), rep("Infravermelho", 5), rep("Indutivo", 5))
emm <- c(1.99, 2.05, 2.41, 2.11, 2.13, 3.31, 2.94, 2.42, 
          2.59, 2.67, 1.78, 1.65, 1.66, 1.62, 1.52)

dados <- data.frame(sensores = as.factor(sensores), emm = emm)

print(dados)

```

## Análise Descritiva

Para a Análise Descritiva, foram calculadas a média (X̄), o desvio padrão (S) e o coeficiente de variação (CV), a fim de caracterizar a variabilidade e o comportamento dos dados.

### Geral

Portanto os valores são: média = 2.19, Desvio Padrão = 0.5272977 e Coeficiente de Variação = 24.07752. 

```{r}

media_geral <- mean(dados$emm)
dp_geral <- sd(dados$emm)
cv_geral <- 100 * dp_geral / media_geral

cat("Média:", media_geral, "\nDesvio Padrão:", dp_geral, "\nCoef. de Variação (CV%):", cv_geral)

```
### Por Tratamento

```{r}

#por tratamento

library(dplyr)

dados %>%
  group_by(sensores) %>%
  summarise(
    media = mean(emm),
    desvio_padrao = sd(emm),
    cv = 100 * sd(emm) / mean(emm)
  )
```

### Boxplot

O sensor Infravermelho apresentou os maiores valores de EMM, além de uma grande variabilidade nos dados, evidenciada pela largura da caixa e pela extensão dos bigodes. Esse comportamento indica uma menor precisão nas medições realizadas por esse tipo de sensor.

Por outro lado, o sensor Indutivo demonstrou os menores valores de erro médio, com pouca variação entre as observações. Embora haja a presença de alguns outliers, sua mediana permanece baixa, sugerindo um desempenho mais estável e preciso.

Já o sensor Ultrassônico ocupou uma posição intermediária, com valores de erro superiores aos do sensor Indutivo, mas inferiores aos do Infravermelho. Sua dispersão também foi moderada, com um outlier acima da mediana.

De modo geral, os resultados indicam que o sensor Indutivo apresentou o melhor desempenho, seguido pelo Ultrassônico. O sensor Infravermelho, por sua vez, mostrou maior instabilidade nas medições, sendo o menos preciso entre os três avaliados.


```{r}

#boxplot

boxplot(emm ~ sensores, data = dados, col = "lightgreen", 
        main = "Boxplot do EMM por Tipo de Sensor", 
        ylab = "Erro Medio de Medição (EMM)")


```

## Análise de Variância

Na Análise de Variância, é necessário definir as hipóteses nula (H0) e alternativa (H1), apresentar a tabela da ANAVA e realizar uma avaliação gráfica dos resíduos para verificar a adequação do modelo.

Para a relação das hipóteses, segue a explicação abaixo: 

H0 = Os sensores têm a mesma média de EMM

H1 = Ao menos um sensor se difere dos outros

### ANAVA

```{r}
modelo <- aov(emm ~ sensores, data = dados)
summary(modelo)


```

Dessa forma, os resultados indicam que o valor de p é significativamente inferior ao nível de significância adotado (Alpha = 0,05), o que permite rejeitar a hipótese nula. Isso evidencia que há, de fato, uma diferença estatisticamente relevante entre os tipos de sensores analisados.

### Análise de Resíduos

```{r}
par(mfrow = c(2,2))
plot(modelo)

```

O gráfico Residuals vs Fitted mostra uma distribuição dos resíduos relativamente próxima da linha zero, o que é desejável. No entanto, observa-se uma leve tendência de inclinação negativa na linha vermelha de ajuste, sugerindo possível pequena violação da suposição de linearidade. Há alguns pontos mais distantes, mas a maioria dos resíduos se concentra em torno da linha, indicando que a variabilidade dos resíduos não aumenta sistematicamente com os valores ajustados.

O gráfico Q-Q indica que os resíduos seguem uma distribuição aproximadamente normal, com a maioria dos pontos alinhados sobre a linha pontilhada. Apenas os dois últimos pontos se desviam mais acentuadamente, mas esse comportamento é considerado aceitável e não compromete significativamente a normalidade dos resíduos.

O gráfico Scale-Location, os resíduos padronizados elevados ao quadrado parecem estar distribuídos de forma razoavelmente homogênea, embora haja uma leve tendência crescente na linha vermelha. Isso sugere uma possível variação leve na homocedasticidade, especialmente nos valores ajustados mais altos, mas não de forma grave. No geral, não há evidência forte de heterocedasticidade.

No gráfico Residuals vs Factor Levels (Constant Leverage) os resíduos estão distribuídos de maneira relativamente equilibrada entre os grupos dos sensores, com a maioria dos pontos próximos à linha zero. Não há indícios claros de violação da independência ou presença de alavancagem excessiva. A simetria e centralização dos resíduos reforçam a adequação do modelo aos dados categóricos.

# Conclusão

A análise realizada permitiu avaliar com clareza o desempenho de diferentes tipos de sensores quanto ao erro médio de medição, utilizando um Delineamento Inteiramente Casualizado (DIC). Por meio da análise descritiva, identificou-se que o sensor Indutivo apresentou os menores valores de EMM e menor variabilidade, destacando-se como o mais preciso entre os três. Em contrapartida, o sensor Infravermelho mostrou os maiores erros médios e a maior dispersão, indicando baixa consistência nas medições. O sensor Ultrassônico situou-se entre os dois extremos, com desempenho intermediário.

A análise de variância (ANOVA) revelou que há diferença significativa entre os sensores, já que o valor de p foi inferior ao nível de significância adotado, permitindo rejeitar a hipótese nula de igualdade entre as médias. A análise gráfica dos resíduos confirmou que as premissas do modelo — como normalidade, homocedasticidade e independência dos erros — foram atendidas de forma satisfatória.

Dessa forma, conclui-se que o tipo de sensor influencia significativamente o erro médio de medição, sendo o sensor Indutivo a alternativa mais precisa e confiável, conforme os dados analisados neste experimento.
=======
---
title: "Relatório 04"
author: "Kaleb Aquino Mileib"
date: "01/05/2025"
header-includes:
  - \usepackage{titling}
  - \pretitle{\begin{center}
    \includegraphics[width=2in,height=2in]{ufsj.png}\LARGE\\}
  - \posttitle{\end{center}}
toc-title: "Sumário"
output:
  
  html_document:
    theme: journal
    highlight: tango
    toc: yes
    number_sections: yes
    includes:
      in_header: logo.html
  pdf_document:
    
    toc: yes
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
--- 

# Objetivo

Neste relatório, deve-se analisar um experimento em DIC (Delineamento Inteiramente Causalizado), realizando a Análise Descritiva geral e de cada tratamento (com média, desvio padrão e coeficiente de variação) e uma análise gráfica de Boxplot. Também é necessário realizar uma Análise de Variância, com hipóteses H0 e H1, tabela de ANAVA, e análise gráfica de resíduos. 

# Desenvolvimento

Para trabalhar neste relatório, será necessário utilizar o banco de dados abaixo proposto pelo professor. Com ele, devemos avaliar o **Erro Quadrático Médio (EQM)** dos 5 algorítmos de controle: **PID, LQR, Fuzzy, Controle Adaptativo e por Redes Neurais**. Nele, temos a estrutura  de **5 tratamentos** (métodos de controle), **6 repetições** para cada e **1 variável de resposta**. 

```{r}
# Banco de dados
controle <- c(rep("PID", 6), rep("LQR", 6), rep("Fuzzy", 6), rep("Adaptativo", 6), rep("Redes Neurais", 6))
eqm <- c(0.322, 0.338, 0.428, 0.354, 0.356, 0.436,
         0.298, 0.229, 0.253, 0.262, 0.329, 0.294,
         0.444, 0.427, 0.387, 0.527, 0.450, 0.302,
         0.345, 0.286, 0.257, 0.299, 0.259, 0.274,
         0.231, 0.199, 0.275, 0.255, 0.216, 0.288)

dados <- data.frame(controle = as.factor(controle), eqm = eqm)

print(dados)

```

## Análise Descritiva

Para a realização da Análise Descritiva, foi necessário realizar a média (X barra), o desvio padrão (S) e o coeficiente de variação (CV). 

```{r}

media_geral <- mean(dados$eqm)
dp_geral <- sd(dados$eqm)
cv_geral <- 100 * dp_geral / media_geral

cat("Média:", media_geral, "\nDesvio Padrão:", dp_geral, "\nCoef. de Variação (CV%):", cv_geral)

```
Conforme é possível ver acima, estes são os valores gerais de média (0.3206667), Desvio Padrão (0.0807996) e Coeficiente de Variação (25.19738). 

```{r}

#por tratamento

library(dplyr)

dados %>%
  group_by(controle) %>%
  summarise(
    media = mean(eqm),
    desvio_padrao = sd(eqm),
    cv = 100 * sd(eqm) / mean(eqm)
  )
```
Acima, é possível ver os dados de Média, Desvio Padrão e Coeficiente de Variância para cada controlador. E segue abaixo o gráfico boxplot por tipo de controle, analisando o erro quadrático médio (EQM) de cada um.

Sobre o gráfico, é possível perceber que os métodos de controle Adaptativo e LQR são bem parecidos, quanto à sua distribuição de EQMs, visto que possuem uma mediana relativamente próxima e variações absolutas semelhantes, apesar do LQR possuir maior distância entre seus limites. 

Também é possível observar que a distribuição dos valores de EQM dos controles por Fuzzy e PID tendem a um dos limites. No caso do Fuzzy, seus EQMs estão mais distribuidos entre a mediana e o primeiro quartil. Já no PID, o contrário se verifica, onde os valores se distribuem mais entre a mediana e o terceiro quartil. 


```{r}

#boxplot

boxplot(eqm ~ controle, data = dados, col = "skyblue", 
        main = "Boxplot do EQM por Tipo de Controle", 
        ylab = "Erro Quadrático Médio (EQM)")


```

## Análise de Variância

Para a Analise de Variância, deve ser estabelecida a relação entre as hipóteses H₀ e H₁, uma tabela ANAVA e uma análise gráfica de resíduos.

Para a relação das hipóteses, segue a explicação abaixo: 

**H₀: μ₁ = μ₂ = μ₃ = μ₄ = μ₅ (os controladores têm a mesma média de EQM)**

**H₁: ao menos um controlador difere significativamente**

Abaixo, podemos ver a tabela ANAVA utilizando a função sugerida pelo professor.

```{r}
modelo <- aov(eqm ~ controle, data = dados)
summary(modelo)


```

Com isso, podemos interpretar os resultados e afirmar que como o valor P é muito menor que o alpha definido (0,05), a hipótese H0 pode ser descartada, confirmando que existe uma diferença significativa entre os tipos de controle. 

```{r}
par(mfrow = c(2,2))
plot(modelo)

```

É possível observar que: 

Sobre o gráfico *Residuals vs fitted*, é possível perceber que há uma aleatoriedade quanto a distribuição dos resíduos ao longo da linha 0, menos nos últimos valores, que possuem alguns outliers e com uma inclinação na linha de fitted em vermelho. 

há uma normalidade da dsitribuição dos resíduos, visto o *Gráfico Q-Q* ser aproximadamente linear, com apenas os dois últimos pontos se destacando, porém nada fora do normal.

O gráfico *Scale Location* apresenta uma homocedasticidade (variância constante) que está, no geral, distribuida de forma aleatória acima e abaixo da linha de regrssão (vermelha), apenas com os primeiros e últimos valores possuindo maior distribuiçãoa baixo da linha.

E por fim, o gráfico *Constant Leverage: Residuals vs Factor Levels* apresenta um tratamento razoavelmente centrado em 0 com uma certa simetria. Portanto, pode-se dizer que os erros estão aleatoriamente distribuidos. 

## Verificação

Em aula, foi pedido para pesquisar como calcular os Graus de Liberdade (GL), Soma dos Quadrados (SQ) e Quadrado Médio (QM) e comparar com os valores dados pelo R no código abaixo: 

```{r}
# Tabela ANOVA manual
SQT <- sum((tapply(dados$eqm, dados$controle, mean) - mean(dados$eqm))^2 * 6) # 6 repetições
SQR <- sum((dados$eqm - fitted(modelo))^2)
SQTotal <- sum((dados$eqm - mean(dados$eqm))^2)

GLT <- length(unique(dados$controle)) - 1
GLR <- length(dados$eqm) - length(unique(dados$controle))
GLTotal <- length(dados$eqm) - 1

QMT <- SQT / GLT
QMR <- SQR / GLR
QMTotal <- QMT + QMR
F <- QMT / QMR

tabela_anova_manual <- data.frame(
  Fonte = c("Tratamento", "Resíduo", "Total"),
  GL = c(GLT, GLR, GLTotal),
  SQ = c(SQT, SQR, SQTotal),
  QM = c(QMT, QMR, QMTotal),
  F = c(F, NA, NA)
)
tabela_anova_manual
```

Portanto, os GL representam a quantidade de informações independentes disponíveis para variarem. O **GL dos tratamentos (GLT)** é feito pelo N° de tratamentos - 1, sendo GLT = 4. O **GL dos resíduos (GLR)** é o N° de observações - N° de tratamentos, que é GLR = 25. O total é a soma dos dois. Comparando com a tabela, os valores indicados pelo R são verdadeiros. 

Sobre a SQ, que significa a variabilidade associada a cada fonte. Ao dividir em dois grupos, **SQ dos Tratamentos (SQT)** e **SQ dos Resíduos (SQR)**, deve-se para o primeiro, calcular a média de cada grupo, subtrair a média geral, elevar ao quadrado e multiplicar pelo número de repetições (6 por grupo), resultando em SQT = 0,132028. Para o segundo, deve-se calcular a diferença entre o valor observado e o valor ajustado e elevar ao quadrado. O resultado é SQR = 0,057301. O total é a soma de ambos. Comparando com a tabela, os valores coincidem.

O Quadrado Médio (QM) é feito pelo cálculo da SQ dividida pelo respectivo GL, representando a variabilidade média. Temos o **Quadrado Médio dos Tratamentos (QMT)** sendo a divisão entre GLT e SQT, resultando em QMT = 0,033007. E temos o **Quadrado Médio dos Resíduos (QMR)** representado pela divisão entre GLR e SQR, com QMR = 0,002292. O total pode ser representado pela soma dos dois, sendo QMTotal = 0,035299. Os resultados coincidem com a tabela. 

# Conclusão

A partir da análise realizada neste relatório, foi possível avaliar e comparar o desempenho de cinco algoritmos de controle (PID, LQR, Fuzzy, Adaptativo e Redes Neurais) quanto ao Erro Quadrático Médio (EQM), utilizando um experimento em Delineamento Inteiramente Casualizado (DIC). A análise descritiva inicial, composta pela média, desvio padrão e coeficiente de variação, forneceu uma visão geral e individual de cada tratamento, permitindo identificar diferenças preliminares nos comportamentos dos métodos de controle avaliados.

O gráfico boxplot complementou a análise descritiva, evidenciando a distribuição dos EQMs em cada tipo de controle. Observou-se que os métodos Adaptativo e LQR apresentaram padrões similares em suas distribuições, enquanto os métodos Fuzzy e PID demonstraram assimetrias distintas, sugerindo variações de desempenho mais específicas nesses algoritmos.

A Análise de Variância (ANOVA) confirmou estatisticamente que há diferença significativa entre os métodos de controle analisados, com valor-p muito inferior ao nível de significância adotado (α = 0,05). Isso indica a rejeição da hipótese nula (H₀), que assumia igualdade entre as médias dos tratamentos, reforçando a conclusão de que ao menos um dos controladores se destaca em relação aos demais.

A análise dos resíduos mostrou que os pressupostos da ANOVA foram razoavelmente atendidos: os resíduos apresentaram distribuição aproximadamente normal, homocedasticidade e ausência de padrões sistemáticos, apesar da presença de alguns valores atípicos. Esses aspectos garantem a confiabilidade dos resultados inferenciais obtidos.

Por fim, a verificação manual dos componentes da ANOVA — graus de liberdade (GL), soma dos quadrados (SQ), quadrado médio (QM) e estatística F — confirmou a consistência dos cálculos realizados pelo R, reforçando a compreensão prática dos conceitos estatísticos envolvidos.

Dessa forma, o experimento permitiu não apenas identificar diferenças significativas entre os métodos de controle, como também consolidar o uso das ferramentas estatísticas para análise de experimentos em DIC, sendo um recurso valioso na comparação de desempenho entre diferentes técnicas.


Sites utilizados de referência para os estudos:
https://fernandafperes.com.br/blog/interpretacao-boxplot/
https://rpubs.com/iabrady/residual-analysis
>>>>>>> 01a1725ccbc5eba373205e912f2727fb33b738d2
